<!DOCTYPE html>
<html lang="pt-BR">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Scanner OMR</title>

<script async src="https://docs.opencv.org/4.5.4/opencv.js"></script>

<style>
body {
  margin: 0;
  background: black;
  overflow: hidden;
}
video, canvas {
  position: absolute;
  width: 100%;
  height: 100%;
  object-fit: cover;
}
#status {
  position: fixed;
  top: 20px;
  width: 100%;
  text-align: center;
  color: white;
  font-size: 18px;
  z-index: 10;
}
#btn {
  position: fixed;
  bottom: 30px;
  left: 50%;
  transform: translateX(-50%);
  padding: 20px 50px;
  font-size: 20px;
  border-radius: 40px;
  background: #00ff00;
  border: none;
  display: none;
}
</style>
</head>

<body>

<div id="status">Buscando marcações...</div>
<video id="video" autoplay playsinline></video>
<canvas id="canvas"></canvas>
<button id="btn">CAPTURAR</button>

<audio id="beep" src="https://assets.mixkit.co/active_storage/sfx/2869/2869-preview.mp3"></audio>

<script>
const video = document.getElementById("video");
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
const status = document.getElementById("status");
const btn = document.getElementById("btn");
const beep = document.getElementById("beep");

function startCamera() {
  navigator.mediaDevices.getUserMedia({
    video: { facingMode: "environment" }
  }).then(stream => {
    video.srcObject = stream;
    video.onloadedmetadata = () => {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      process();
    };
  });
}

function process() {
  let src = new cv.Mat(video.videoHeight, video.videoWidth, cv.CV_8UC4);
  let gray = new cv.Mat();
  let blurred = new cv.Mat();
  let thresh = new cv.Mat();
  let contours = new cv.MatVector();
  let hierarchy = new cv.Mat();

  const cap = new cv.VideoCapture(video);

  function loop() {
    cap.read(src);

    cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
    cv.GaussianBlur(gray, blurred, new cv.Size(5,5), 0);
    cv.threshold(blurred, thresh, 100, 255, cv.THRESH_BINARY_INV);

    cv.findContours(thresh, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

    ctx.clearRect(0, 0, canvas.width, canvas.height);

    let found = false;

    for (let i = 0; i < contours.size(); i++) {
      let cnt = contours.get(i);
      let area = cv.contourArea(cnt);

      if (area > 400 && area < 2500) {
        let rect = cv.boundingRect(cnt);

        ctx.strokeStyle = "lime";
        ctx.lineWidth = 3;
        ctx.strokeRect(rect.x, rect.y, rect.width, rect.height);

        found = true;
      }
    }

    if (found) {
      status.innerText = "Marcações detectadas!";
      status.style.color = "#00ff00";
      btn.style.display = "block";
      beep.play().catch(()=>{});
    } else {
      status.innerText = "Buscando marcações...";
      status.style.color = "white";
      btn.style.display = "none";
    }

    requestAnimationFrame(loop);
  }

  loop();
}

btn.onclick = () => {
  alert("OMR capturado com sucesso!");
};

cv['onRuntimeInitialized'] = startCamera;
</script>

</body>
</html>
