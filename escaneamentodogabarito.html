<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Scanner OMR Final</title>
    <script src="https://docs.opencv.org/4.5.4/opencv.js"></script>
    <style>
        body { margin: 0; background: #000; font-family: sans-serif; overflow: hidden; color: white; }
        #loading { position: fixed; inset: 0; background: #1a1a1a; display: flex; justify-content: center; align-items: center; z-index: 1000; }
        
        /* Câmera e Canvas ocupando a tela toda */
        .container { position: relative; width: 100vw; height: 100vh; }
        video, #canvas-draw { position: absolute; top: 0; left: 0; width: 100%; height: 100%; object-fit: cover; }
        
        /* Camada de Debug (O que o algoritmo vê em P&B) */
        #canvas-debug { position: absolute; bottom: 10px; right: 10px; width: 120px; height: 90px; border: 2px solid red; z-index: 30; background: #000; }

        .ui { position: absolute; top: 20px; width: 100%; text-align: center; z-index: 20; pointer-events: none; }
        #btn-capture { 
            position: absolute; bottom: 40px; left: 50%; transform: translateX(-50%);
            padding: 20px 40px; background: #00ff00; color: #000; border: none;
            border-radius: 50px; font-weight: bold; font-size: 1.2rem; display: none; z-index: 40; cursor: pointer;
        }

        /* Popup */
        #popup { position: fixed; inset: 0; background: rgba(0,0,0,0.9); display: none; flex-direction: column; align-items: center; justify-content: center; z-index: 5000; }
        #popup img { max-width: 90%; max-height: 70%; border: 2px solid #00ff00; }
    </style>
</head>
<body>

<div id="loading">Carregando OpenCV...</div>

<div class="container">
    <div class="ui">
        <h2 id="status">Buscando Bolinhas...</h2>
    </div>
    <video id="video" playsinline muted></video>
    <canvas id="canvas-draw"></canvas>
    <canvas id="canvas-debug"></canvas>
    <button id="btn-capture">CAPTURAR GABARITO</button>
</div>

<div id="popup">
    <h1>Leitura Concluída</h1>
    <p id="total" style="font-size: 24px; color: #00ff00; margin: 15px;"></p>
    <img id="foto-result">
    <button onclick="location.reload()" style="margin-top:20px; padding: 15px;">NOVA LEITURA</button>
</div>

<audio id="som" src="https://assets.mixkit.co/active_storage/sfx/2869/2869-preview.mp3"></audio>

<script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas-draw');
    const debugCanvas = document.getElementById('canvas-debug');
    const btn = document.getElementById('btn-capture');
    const statusText = document.getElementById('status');
    let markers = [];

    // 1. Iniciar Câmera
    async function start() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ 
                video: { facingMode: "environment", width: 640, height: 480 } 
            });
            video.srcObject = stream;
            video.play();
            document.getElementById('loading').style.display = 'none';
            setTimeout(process, 1000);
        } catch (e) { alert("Câmera bloqueada. Use HTTPS."); }
    }

    function process() {
        let src = new cv.Mat(video.videoHeight, video.videoWidth, cv.CV_8UC4);
        let gray = new cv.Mat();
        let thresh = new cv.Mat();
        let contours = new cv.MatVector();
        let hierarchy = new cv.Mat();
        let cap = new cv.VideoCapture(video);

        function loop() {
            try {
                cap.read(src);
                cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
                
                // Redução de ruído e Threshold Adaptativo (Pega preto no branco)
                cv.GaussianBlur(gray, gray, new cv.Size(5, 5), 0);
                cv.adaptiveThreshold(gray, thresh, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV, 11, 4);
                
                // Mostra no quadradinho vermelho o que o robô está vendo
                cv.imshow('canvas-debug', thresh);

                cv.findContours(thresh, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

                const ctx = canvas.getContext('2d');
                canvas.width = video.clientWidth;
                canvas.height = video.clientHeight;
                ctx.clearRect(0, 0, canvas.width, canvas.height);

                markers = [];
                const sx = canvas.width / src.cols;
                const sy = canvas.height / src.rows;

                for (let i = 0; i < contours.size(); i++) {
                    let cnt = contours.get(i);
                    let area = cv.contourArea(cnt);
                    let rect = cv.boundingRect(cnt);
                    let ratio = rect.width / rect.height;

                    // Filtro de tamanho: Ajuste aqui se não detectar (area > 200)
                    if (area > 150 && area < 5000 && ratio > 0.7 && ratio < 1.3) {
                        markers.push(rect);
                        ctx.beginPath();
                        ctx.arc((rect.x + rect.width/2)*sx, (rect.y + rect.height/2)*sy, (rect.width/2)*sx, 0, 2*Math.PI);
                        ctx.fillStyle = "rgba(0, 255, 0, 0.7)";
                        ctx.fill();
                    }
                }

                if (markers.length >= 1) {
                    statusText.innerText = markers.length + " MARCAS ENCONTRADAS";
                    btn.style.display = "block";
                } else {
                    statusText.innerText = "APONTE PARA O GABARITO";
                    btn.style.display = "none";
                }

                requestAnimationFrame(loop);
            } catch (e) { requestAnimationFrame(loop); }
        }
        loop();
    }

    btn.onclick = () => {
        document.getElementById('som').play();
        const finalCanvas = document.createElement('canvas');
        finalCanvas.width = video.videoWidth;
        finalCanvas.height = video.videoHeight;
        const fctx = finalCanvas.getContext('2d');
        fctx.drawImage(video, 0, 0);
        
        markers.forEach(r => {
            fctx.beginPath();
            fctx.arc(r.x + r.width/2, r.y + r.height/2, r.width/2, 0, 2*Math.PI);
            fctx.fillStyle = "rgba(0, 255, 0, 0.8)";
            fctx.fill();
        });

        document.getElementById('foto-result').src = finalCanvas.toDataURL();
        document.getElementById('total').innerText = markers.length + " bolinhas identificadas";
        document.getElementById('popup').style.display = "flex";
    };

    // Esperar OpenCV carregar
    if (cv.Mat) start(); else cv.onRuntimeInitialized = start;
</script>
</body>
</html>
